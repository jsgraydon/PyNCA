---
title: "PyNCA: Noncompartmental Analysis In Python"
author: "James S. Graydon"
institute: "Columbia University, GSAS, Biotechnology"
date: today
date-format: "D MMMM YYYY"  
format: 
  revealjs:
    theme: moon
    css: styles.css
    slide-number: true
    scrollable: true
    highlight-style: github
    havigation_mode: vertical
favicon: favicon.ico
---

```{r init, echo=FALSE, include=FALSE}
library(dplyr)
library(flextable)
library(plotly)
library(readr)

df_dummy <- read_csv("../pk_dummy_iv_bolus_1cmt.csv", show_col_types = FALSE) 
```


## Introduction: Pharmacokinetics

-   Pharmacokinetic (PK) data is routinely collected and analyzed in drug development
    -   In simple terms, PK data represents the **concentration** of drug in a given compartment over time
    -   PK data help scientists understand the distribution and activity of a drug
    -   PK data are also used to establish the duration of the drug's persistence in the body and safety profile
    
## Sample of PK data

```{r sample_data, echo=FALSE}
df_dummy |>
  select(-TREND) |>
  head(5) |>
  flextable() |>
  theme_alafoli() |>
  color(part = "all", color = "ivory") |>
  fontsize(part = "all", size = 16) |>
  width(j = 1:4, width = 2)
```


## Introduction: Noncompartmental analysis

-   Noncompartmental analysis (NCA) is a widely used methodology for quantifying PK data
    -   NCAs typically return values such as:
        -   Half-life (t~1/2~)
        -   Maximum concentration (C~max~)
        -   Time to C~max~ (T~max~)
        -   Volume of distribution (V~d~)
        -   Clearance rate (CL)
        -   Area under the concentration-time curve (AUC)
-   More sophisticated (and complicated) methods allow for further characterization of PK
    -   NCA, due to simplicity/low cost/ease of use, is still a standard part of all drug studies

## Why am I doing this?

-   NCA is a simple method, but many pharmacologists lack experience with or access to software to run it
-   No Python-based NCA solution exists
-   A simple, easy-to-use, secure option may allow more users to quickly perform NCAs

## Features

-   **pk_dummy_data:** a class for generating "dummy" PK data for use in PyNCA
-   **pk_data:** a class containing methods for analyzing and visualizing PK data
    -   `--summarize`
    -   `--plot`
    -   `--nca`
    
## ```--help```

Input:
```
 python -m pynca --help
```

Output:
```
usage: __main__.py [-h] [--generate] [--dummy_n_ids D_NIDS] [--dummy_times D_TIMES [D_TIMES ...]]
                   [--dummy_dose D_DOSE] [--dummy_half_life D_T12] [-f DATASET_PATH] [-s] [-p] [--plot_mean]
                   [--log_scale] [--auc_start AUC_START] [--auc_end AUC_END]
                   [--terminal_times TERM_TIMES [TERM_TIMES ...]] [--auc] [--nca] [--report REPORT_PATH]

PyNCA: Noncompartmental Analysis in Python

options:
  -h, --help            show this help message and exit
  --generate            generates a dummy dataset of PK data
  --dummy_n_ids D_NIDS  int: sets number of ID values for the dummy dataset (requires --generate)
  --dummy_times D_TIMES [D_TIMES ...]
                        list (space-seperated): sets sampling times for dummy dataset (requires --generate)
  --dummy_dose D_DOSE   float: sets dose for dummy dataset (requires --generate)
  --dummy_half_life D_T12
                        float: sets half-life for dummy dataset (requires --generate)
  -f DATASET_PATH, --file DATASET_PATH
                        str: provide file path to a CSV file
  -s, --summarize       summarize the data (requires -f/--file)
  -p, --plot            plot the raw data (requires -f/--file)
  --plot_mean           option to summarize the data (mean, SD) before plotting (requires -p/--plot)
  --log_scale           option to plot the data on a semi-log scale (requires -p/--plot)
  --auc_start AUC_START
                        int: first time value to include in AUC (requires -r/--report)
  --auc_end AUC_END     int: last time value to include in AUC (requires -r/--report)
  --terminal_times TERM_TIMES [TERM_TIMES ...]
                        list (space-separated): list of times for half-life calculation (requires -r/--report)
  --auc                 calculates AUC between --auc_start and --auc_end
  --nca                 perform full NCA (requires -f/--file)
  --report REPORT_PATH  str: name for saved NCA results

Example usage:

  # Generate a dummy dataset
  python -m pynca --generate --dummy_n_ids 10 --dummy_times 0 1 2 4 8 --dummy_dose 100 --dummy_half_life 3.5

  # Load a dataset and summarize
  python -m pynca -f [data.csv] --summarize

  # Plot the raw data with a semi-log scale
  python -m pynca -f [data.csv] -p --log_scale

  # Perform a full NCA analysis
  python -m pynca -f [data.csv] --nca --auc_start 0 --auc_end 8 --terminal_times 1 2 4

For more details, please see the README file.
```

## pk_dummy_data

Input:
``` 
python -m pynca --generate --dummy_n_ids 10 --dummy_times 0 0.5 1 2 6 12 24 48 72 168 --dummy_dose 100 --dummy_half_life 12
```
Output:
```{r data_example, echo=FALSE}
df_dummy |>
  head(5) |>
  flextable() |>
  theme_alafoli() |>
  color(part = "all", color = "ivory") |>
  fontsize(part = "all", size = 16) |>
  width(j = 1:5, width = 2)
```

## pk_data: --summarize

Input:
``` 
python -m pynca -f "pk_dummy_iv_bolus_1cmt.csv" --summarize
```

Output:
```{r summ, echo=FALSE}
df_dummy |>
  summarize(across(CONC, 
                   list(mean = mean, 
                        std = sd, 
                        median = median, 
                        min = min, 
                        max = max), 
                   .names = "{.fn}"), 
            .by = TIME) |>
  flextable() |>
  theme_alafoli() |>
  color(part = "all", color = "ivory") |>
  fontsize(part = "all", size = 16) |>
  width(j = 1:5, width = 1.8)
```


## pk_data: --plot

Input:
```
python -m pynca -f "pk_dummy_iv_bolus_1cmt.csv" --plot --log_scale
```

Output:
```{r plotly, warning=FALSE, message=FALSE}
plot_ly(data = df_dummy,
        x = ~TIME,
        y = ~CONC,
        color = ~as.factor(ID),
        type = "scatter") |>
  add_lines(showlegend = FALSE) |>
  layout(
    title = "Individual PK concentration profiles",
    xaxis = list(title = "Time"),
    yaxis = list(title = "Concentration")
  )
```


## pk_data: --nca

Input:
```
python -m pynca -f "pk_dummy_iv_bolus_1cmt.csv" --nca --auc_start 0 --auc_end 168 --terminal_times 24 48 72
```

Output:
```
Results of NCA:

Cmax: 
      mean        sd    min    max       Q1  median        Q3    IQR
0  101.566  5.769795  93.88  110.0  96.8125  100.82  105.5775  8.765


Tmax: 
   mean   sd  min  max   Q1  median   Q3  IQR
0   0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0


t1/2: 
        mean        sd        min        max         Q1     median         Q3       IQR
0  12.584638  0.035497  12.529479  12.653947  12.562085  12.585565  12.605511  0.043425


AUC(0-168): 
      mean         sd     min        max          Q1      median          Q3      IQR
0  1847.02  34.524068  1771.0  1888.8725  1831.75125  1852.53375  1866.72875  34.9775


Vd: 
       mean        sd       min      max        Q1    median        Q3       IQR
0  0.987407  0.055319  0.909091  1.06519  0.947299  0.991974  1.032944  0.085645


CL: 
       mean        sd       min       max       Q1   median        Q3       IQR
0  0.054159  0.001029  0.052942  0.056465  0.05357  0.05398  0.054593  0.001023

```

## module.py

```
import pandas as pd
import plotly.express as px
import numpy as np
from scipy.stats import linregress

class pk_dummy_data:
    def __init__(self, n_ids:int, times:list, dose:float):
        self.n_ids = n_ids
        self.times = times
        self.dose = dose

        self.len_times = len(times)
    
        time_seq = np.array(times)
        dose_seq = np.array([dose])
        self.time_seq = time_seq

        while len(dose_seq) < self.len_times:
            dose_seq = np.append(dose_seq, 0)

        id_col = np.repeat(np.arange(1, n_ids + 1), self.len_times)
        time_col = np.tile(time_seq, n_ids)
        dose_col = np.tile(dose_seq, n_ids)

        self.df = pd.DataFrame({
            "ID": id_col,
            "TIME": time_col,
            "DOSE": dose_col
        })

    def iv_bolus_1cmt(self, half_life:float):
        k = np.log(2) / half_life  # Elimination rate constant
        C0 = self.dose  # Initial concentration

        conc_trend = C0 * np.exp(-k * self.time_seq)

        conc_data = []
        for _ in range(self.n_ids):
            variability = np.random.normal(1, 0.05, size=len(conc_trend))
            variability = np.clip(variability, 0.9, 1.1)
            conc = np.round(conc_trend * variability, 2)

            # Ensure concentrations consistently decrease
            conc_monotonic = [conc[0]]
            for val in conc[1:]:
                conc_monotonic.append(min(conc_monotonic[-1], val))

            conc_data.extend(conc_monotonic)

        self.df = self.df.assign(TREND=np.tile(np.round(conc_trend, 2), self.n_ids))
        self.df["CONC"] = conc_data

        return self.df

class pk_data:
    def __init__(self, data):
        '''Initialize the pk_data object. Accepts either a DataFrame or a CSV file path.'''
        if isinstance(data, str):  # If a file path is given
            self.df = pd.read_csv(data)
        elif isinstance(data, pd.DataFrame):
            self.df = data
        else:
            raise ValueError("Input data must be a DataFrame or a path to a CSV file.")

        self.list_ids = self.df['ID'].unique()

    def summarize(self):
        summ = self.df.groupby('TIME')['CONC'].agg(["count", "mean", "std", "median", "min", "max"]).reset_index()
        return summ
        
    def summ_stats(self, vals:list, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']):
        # Ensures user requests valid stats
        for i in stat:
            if i not in ['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']:
                raise Exception("""Unsupported statistic. Please enter an array of one or more of 'mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', or 'IQR'.
               Leave blank to calculate all statistics.""")
    
        vals_series = pd.Series(vals)
    
        stats = {
                'mean': vals_series.mean(),
                'sd': vals_series.std(),
                'min': vals_series.min(),
                'max': vals_series.max(),
                'Q1': vals_series.quantile(0.25),
                'median': vals_series.median(),
                'Q3': vals_series.quantile(0.75),
                'IQR': vals_series.quantile(0.75) - vals_series.quantile(0.25)
        }
    
        stats = {k: v for k, v in stats.items() if k in stat}   
    
        return pd.DataFrame([stats])

    def half_life(self, term_elim_times:list, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']):
        half_lives = []
        for ID in self.list_ids:
            subset = self.df.loc[self.df['ID'] == ID]
            ln_conc = np.log(subset['CONC'])
            slope, _, r_value, _, _ = linregress(subset['TIME'], ln_conc)
            if slope >= 0:
                continue  # biologically invalid slope, skip
            half_life = np.log(2) / -slope
            half_lives.append(half_life)
        return self.summ_stats(half_lives, stat=stat)

    def cmax(self, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']):
        cmax_vals = self.df.groupby('ID')['CONC'].max()
        return self.summ_stats(cmax_vals, stat=stat)

    def tmax(self, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']):
        tmax_vals = []
        for ID in self.list_ids:
            subset = self.df.loc[self.df['ID'] == ID]
            tmax = subset.loc[subset['CONC'] == subset['CONC'].max()]['TIME'].iloc[0]
            tmax_vals.append(tmax)
        return self.summ_stats(tmax_vals, stat=stat)

    def auc(self, start:int, end:int, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR'], ind=False):
        auc_vals = []
        for ID in self.list_ids:
            subset_id = self.df.loc[self.df['ID'] == ID]
            subset_time = subset_id[(subset_id['TIME'] >= start) & (subset_id['TIME'] <= end)]
            auc = np.trapezoid(subset_time['CONC'], subset_time['TIME'])
            auc_vals.append(auc)

        if ind:
            return auc_vals
        else:
            return self.summ_stats(auc_vals, stat=stat)

    def vd(self, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR'], silence_message=False):
        if not silence_message:
            print("NB: The current iteration of 'vd()' only works for a single bolus dose given at 'TIME' == 0.")
        
        vd_vals = []
        for ID in self.list_ids:
            subset = self.df.loc[(self.df['ID'] == ID) & (self.df['TIME'] == 0)]
            dose = subset['DOSE'].iloc[0]
            c0 = subset['CONC'].iloc[0]
            vd = dose / c0
            vd_vals.append(vd)
        return self.summ_stats(vd_vals, stat=stat)

    def cl(self, start, end, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR'], silence_message=False):
        if not silence_message:
            print("NB: The current iteration of 'cl()' only works for a single bolus dose given at 'TIME' == 0.")
            
        subset = self.df.loc[self.df['DOSE'] != 0].copy().reset_index()
        auc = self.auc(start=start, end=end, ind=True)
        cl_vals = subset['DOSE'] / auc
        return self.summ_stats(cl_vals, stat=stat)
    
    def plot(self, summarized=False, log_scale=False):
        if summarized:
            summary = self.summarize()
            fig = px.line(summary, x="TIME", y="mean", error_y="std", markers=True, log_y=log_scale,
                          title="Mean (SD) PK concentration profile")
        else:
            fig = px.line(self.df, x="TIME", y="CONC", color="ID", markers=True, log_y=log_scale,
                          title="Individual PK concentration profiles")
        
        fig.update_layout(xaxis_title="Time", yaxis_title="Concentration")
        return fig

    def report(self, term_elim_times:list, start, end):
        print(f"Summary of PK data: \n{self.summarize()}\n\n")
        print("Results of NCA:\n")
        print(f"Cmax: \n{self.cmax()}\n\n")
        print(f"Tmax: \n{self.tmax()}\n\n")
        print(f"t1/2: \n{self.half_life(term_elim_times=term_elim_times)}\n\n")
        print(f"AUC({start}-{end}): \n{self.auc(start=start, end=end)}\n\n")
        print(f"Vd: \n{self.vd(silence_message=True)}\n\n")
        print(f"CL: \n{self.cl(start=start, end = end, silence_message=True)}\n\n")
```