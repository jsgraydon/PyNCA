{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1eb1ca-c1f2-4374-9c1e-a644a297b47c",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9105735-4665-4a6d-9430-6f54dd80104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d4fe9-bcfb-46b1-8870-a486169c1a7b",
   "metadata": {},
   "source": [
    "## Generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ac95cb79-0a2a-4e8f-aa85-cefc84985a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DOSE</th>\n",
       "      <th>TREND</th>\n",
       "      <th>CONC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.00</td>\n",
       "      <td>102.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>99.79</td>\n",
       "      <td>102.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.59</td>\n",
       "      <td>96.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.18</td>\n",
       "      <td>93.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.55</td>\n",
       "      <td>90.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  TIME  DOSE   TREND    CONC\n",
       "0   1   0.0   100  100.00  102.14\n",
       "1   1   0.5     0   99.79  102.14\n",
       "2   1   1.0     0   99.59   96.66\n",
       "3   1   2.0     0   99.18   93.78\n",
       "4   1   6.0     0   97.55   90.45"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class pk_dummy_data:\n",
    "    def __init__(self, n_ids:int, times:list, dose:list):\n",
    "        self.n_ids = n_ids\n",
    "        self.times = times\n",
    "        self.dose = dose\n",
    "\n",
    "        self.len_times = len(times)\n",
    "\n",
    "        if len(dose) != 1:\n",
    "            raise Exception(f\"Only a single dose can be enetered; {len_dose} provided.\")\n",
    "    \n",
    "        time_seq = np.array(times)\n",
    "        dose_seq = np.array(dose)\n",
    "        self.time_seq = time_seq\n",
    "\n",
    "        while len(dose_seq) < self.len_times:\n",
    "            dose_seq = np.append(dose_seq, 0)\n",
    "\n",
    "        id_col = np.repeat(np.arange(1, n_ids + 1), self.len_times)\n",
    "        time_col = np.tile(time_seq, n_ids)\n",
    "        dose_col = np.tile(dose_seq, n_ids)\n",
    "\n",
    "        self.df = pd.DataFrame({\n",
    "            \"ID\": id_col,\n",
    "            \"TIME\": time_col,\n",
    "            \"DOSE\": dose_col\n",
    "        })\n",
    "\n",
    "    def iv_bolus_1cmt(self, half_life:float):\n",
    "        k = np.log(2) / half_life  # Elimination rate constant\n",
    "        C0 = self.dose  # Initial concentration\n",
    "\n",
    "        conc_trend = C0 * np.exp(-k * self.time_seq)\n",
    "\n",
    "        conc_data = []\n",
    "        for _ in range(self.n_ids):\n",
    "            variability = np.random.normal(1, 0.05, size=len(conc_trend))\n",
    "            variability = np.clip(variability, 0.9, 1.1)\n",
    "            conc = np.round(conc_trend * variability, 2)\n",
    "\n",
    "            # Ensure concentrations consistently decrease\n",
    "            conc_monotonic = [conc[0]]\n",
    "            for val in conc[1:]:\n",
    "                conc_monotonic.append(min(conc_monotonic[-1], val))\n",
    "\n",
    "            conc_data.extend(conc_monotonic)\n",
    "\n",
    "        self.df = self.df.assign(TREND=np.tile(np.round(conc_trend, 2), self.n_ids))\n",
    "        self.df[\"CONC\"] = conc_data\n",
    "\n",
    "        return self.df\n",
    "\n",
    "pk = pk_dummy_data(n_ids=10, times=[0, 0.5, 1, 2, 6, 12, 24, 48, 72, 96, 168, 336, 840, 1344], dose=[100])\n",
    "df = pk.iv_bolus_1cmt(half_life = 168)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74761e-3470-44c8-9bc5-6ed62124081a",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "10093fc1-6438-4956-810b-0e587277813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of PK data:\n",
      "      TIME  count    mean       std  median    min     max\n",
      "0      0.0     10  97.968  5.287122  96.765  93.16  110.00\n",
      "1      0.5     10  95.680  3.574906  94.905  89.81  102.14\n",
      "2      1.0     10  94.970  2.539234  94.905  89.81   98.32\n",
      "3      2.0     10  93.569  1.735994  93.880  89.81   95.61\n",
      "4      6.0     10  92.624  2.200193  93.515  89.22   95.61\n",
      "5     12.0     10  91.527  2.058274  90.825  89.22   95.61\n",
      "6     24.0     10  88.586  3.206591  89.515  82.44   92.84\n",
      "7     48.0     10  81.306  3.098068  82.310  74.67   84.63\n",
      "8     72.0     10  73.143  2.938197  73.330  66.87   77.34\n",
      "9     96.0     10  67.105  2.665605  67.785  60.57   70.17\n",
      "10   168.0     10  50.304  2.614393  49.920  45.96   55.00\n",
      "11   336.0     10  24.748  0.914887  24.575  23.58   26.33\n",
      "12   840.0     10   3.061  0.164280   3.020   2.90    3.34\n",
      "13  1344.0     10   0.397  0.016364   0.400   0.36    0.41\n",
      "\n",
      "\n",
      "Cmax: \n",
      "     mean        sd    min    max      Q1  median       Q3     IQR\n",
      "0  97.968  5.287122  93.16  110.0  93.875  96.765  99.8575  5.9825\n",
      "\n",
      "\n",
      "Tmax: \n",
      "   mean   sd  min  max   Q1  median   Q3  IQR\n",
      "0   0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0\n",
      "\n",
      "\n",
      "t1/2: \n",
      "         mean        sd         min         max         Q1      median  \\\n",
      "0  169.307614  1.346666  166.421837  171.232185  168.84859  169.143202   \n",
      "\n",
      "           Q3       IQR  \n",
      "0  169.961712  1.113122  \n",
      "\n",
      "\n",
      "AUC(0-840): \n",
      "        mean          sd       min         max           Q1       median  \\\n",
      "0  25309.889  322.132383  24738.88  25722.2125  25063.24625  25344.76875   \n",
      "\n",
      "         Q3        IQR  \n",
      "0  25595.85  532.60375  \n",
      "\n",
      "\n",
      "Vd: \n",
      "      mean        sd       min       max        Q1   median        Q3  \\\n",
      "0  1.02328  0.052339  0.909091  1.073422  1.001429  1.03364  1.065246   \n",
      "\n",
      "        IQR  \n",
      "0  0.063817  \n",
      "\n",
      "\n",
      "CL: \n",
      "       mean        sd       min       max        Q1    median       Q3  \\\n",
      "0  0.003952  0.000051  0.003888  0.004042  0.003907  0.003946  0.00399   \n",
      "\n",
      "        IQR  \n",
      "0  0.000083  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# PyNCA: Noncompartmental Analysis in Python\n",
    "# Copyright (c) 2025 James S. Graydon\n",
    "# Licensed under the MIT License (see LICENSE file)\n",
    "\n",
    "\"\"\"\n",
    "Command line interface to PyNCA\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "class pk_dummy_data:\n",
    "    def __init__(self, n_ids:int, times:list, dose:float):\n",
    "        self.n_ids = n_ids\n",
    "        self.times = times\n",
    "        self.dose = dose\n",
    "\n",
    "        self.len_times = len(times)\n",
    "    \n",
    "        time_seq = np.array(times)\n",
    "        dose_seq = np.array([dose])\n",
    "        self.time_seq = time_seq\n",
    "\n",
    "        while len(dose_seq) < self.len_times:\n",
    "            dose_seq = np.append(dose_seq, 0)\n",
    "\n",
    "        id_col = np.repeat(np.arange(1, n_ids + 1), self.len_times)\n",
    "        time_col = np.tile(time_seq, n_ids)\n",
    "        dose_col = np.tile(dose_seq, n_ids)\n",
    "\n",
    "        self.df = pd.DataFrame({\n",
    "            \"ID\": id_col,\n",
    "            \"TIME\": time_col,\n",
    "            \"DOSE\": dose_col\n",
    "        })\n",
    "\n",
    "    def iv_bolus_1cmt(self, half_life:float):\n",
    "        k = np.log(2) / half_life  # Elimination rate constant\n",
    "        C0 = self.dose  # Initial concentration\n",
    "\n",
    "        conc_trend = C0 * np.exp(-k * self.time_seq)\n",
    "\n",
    "        conc_data = []\n",
    "        for _ in range(self.n_ids):\n",
    "            variability = np.random.normal(1, 0.05, size=len(conc_trend))\n",
    "            variability = np.clip(variability, 0.9, 1.1)\n",
    "            conc = np.round(conc_trend * variability, 2)\n",
    "\n",
    "            # Ensure concentrations consistently decrease\n",
    "            conc_monotonic = [conc[0]]\n",
    "            for val in conc[1:]:\n",
    "                conc_monotonic.append(min(conc_monotonic[-1], val))\n",
    "\n",
    "            conc_data.extend(conc_monotonic)\n",
    "\n",
    "        self.df = self.df.assign(TREND=np.tile(np.round(conc_trend, 2), self.n_ids))\n",
    "        self.df[\"CONC\"] = conc_data\n",
    "\n",
    "        return self.df\n",
    "\n",
    "class pk_data:\n",
    "    def __init__(self, data):\n",
    "        '''Initialize the pk_data object. Accepts either a DataFrame or a CSV file path.'''\n",
    "        if isinstance(data, str):  # If a file path is given\n",
    "            self.df = pd.read_csv(data)\n",
    "        elif isinstance(data, pd.DataFrame):\n",
    "            self.df = data\n",
    "        else:\n",
    "            raise ValueError(\"Input data must be a DataFrame or a path to a CSV file.\")\n",
    "\n",
    "        self.list_ids = self.df['ID'].unique()\n",
    "\n",
    "    def summarize(self):\n",
    "        summ = self.df.groupby('TIME')['CONC'].agg([\"count\", \"mean\", \"std\", \"median\", \"min\", \"max\"]).reset_index()\n",
    "        return summ\n",
    "        \n",
    "    def summ_stats(self, vals:list, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']):\n",
    "        # Ensures user requests valid stats\n",
    "        for i in stat:\n",
    "            if i not in ['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']:\n",
    "                raise Exception(\"\"\"Unsupported statistic. Please enter an array of one or more of 'mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', or 'IQR'.\n",
    "               Leave blank to calculate all statistics.\"\"\")\n",
    "    \n",
    "        vals_series = pd.Series(vals)\n",
    "    \n",
    "        stats = {\n",
    "                'mean': vals_series.mean(),\n",
    "                'sd': vals_series.std(),\n",
    "                'min': vals_series.min(),\n",
    "                'max': vals_series.max(),\n",
    "                'Q1': vals_series.quantile(0.25),\n",
    "                'median': vals_series.median(),\n",
    "                'Q3': vals_series.quantile(0.75),\n",
    "                'IQR': vals_series.quantile(0.75) - vals_series.quantile(0.25)\n",
    "        }\n",
    "    \n",
    "        stats = {k: v for k, v in stats.items() if k in stat}   \n",
    "    \n",
    "        return pd.DataFrame([stats])\n",
    "\n",
    "    def half_life(self, term_elim_times:list, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']):\n",
    "        half_lives = []\n",
    "        for ID in self.list_ids:\n",
    "            subset = self.df.loc[self.df['ID'] == ID]\n",
    "            ln_conc = np.log(subset['CONC'])\n",
    "            slope, _, r_value, _, _ = linregress(subset['TIME'], ln_conc)\n",
    "            if slope >= 0:\n",
    "                continue  # biologically invalid slope, skip\n",
    "            half_life = np.log(2) / -slope\n",
    "            half_lives.append(half_life)\n",
    "        return self.summ_stats(half_lives, stat=stat)\n",
    "\n",
    "    def cmax(self, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']):\n",
    "        cmax_vals = self.df.groupby('ID')['CONC'].max()\n",
    "        return self.summ_stats(cmax_vals, stat=stat)\n",
    "\n",
    "    def tmax(self, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR']):\n",
    "        tmax_vals = []\n",
    "        for ID in self.list_ids:\n",
    "            subset = self.df.loc[self.df['ID'] == ID]\n",
    "            tmax = subset.loc[subset['CONC'] == subset['CONC'].max()]['TIME'].iloc[0]\n",
    "            tmax_vals.append(tmax)\n",
    "        return self.summ_stats(tmax_vals, stat=stat)\n",
    "\n",
    "    def auc(self, start:int, end:int, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR'], ind=False):\n",
    "        auc_vals = []\n",
    "        for ID in self.list_ids:\n",
    "            subset_id = self.df.loc[self.df['ID'] == ID]\n",
    "            subset_time = subset_id[(subset_id['TIME'] >= start) & (subset_id['TIME'] <= end)]\n",
    "            auc = np.trapezoid(subset_time['CONC'], subset_time['TIME'])\n",
    "            auc_vals.append(auc)\n",
    "\n",
    "        if ind:\n",
    "            return auc_vals\n",
    "        else:\n",
    "            return self.summ_stats(auc_vals, stat=stat)\n",
    "\n",
    "    def vd(self, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR'], silence_message=False):\n",
    "        if not silence_message:\n",
    "            print(\"NB: The current iteration of 'vd()' only works for a single bolus dose given at 'TIME' == 0.\")\n",
    "        \n",
    "        vd_vals = []\n",
    "        for ID in self.list_ids:\n",
    "            subset = self.df.loc[(self.df['ID'] == ID) & (self.df['TIME'] == 0)]\n",
    "            dose = subset['DOSE'].iloc[0]\n",
    "            c0 = subset['CONC'].iloc[0]\n",
    "            vd = dose / c0\n",
    "            vd_vals.append(vd)\n",
    "        return self.summ_stats(vd_vals, stat=stat)\n",
    "\n",
    "    def cl(self, start, end, stat=['mean', 'sd', 'min', 'max', 'Q1', 'median', 'Q3', 'IQR'], silence_message=False):\n",
    "        if not silence_message:\n",
    "            print(\"NB: The current iteration of 'cl()' only works for a single bolus dose given at 'TIME' == 0.\")\n",
    "            \n",
    "        subset = self.df.loc[self.df['DOSE'] != 0].copy().reset_index()\n",
    "        auc = self.auc(start=start, end=end, ind=True)\n",
    "        cl_vals = subset['DOSE'] / auc\n",
    "        return self.summ_stats(cl_vals, stat=stat)\n",
    "    \n",
    "    def plot(self, summarized=False, log_scale=False):\n",
    "        if summarized:\n",
    "            summary = self.summarize()\n",
    "            fig = px.line(summary, x=\"TIME\", y=\"mean\", error_y=\"std\", markers=True, log_y=log_scale,\n",
    "                          title=\"Mean (SD) PK concentration profile\")\n",
    "        else:\n",
    "            fig = px.line(self.df, x=\"TIME\", y=\"CONC\", color=\"ID\", markers=True, log_y=log_scale,\n",
    "                          title=\"Individual PK concentration profiles\")\n",
    "        \n",
    "        fig.update_layout(xaxis_title=\"Time\", yaxis_title=\"Concentration\")\n",
    "        return fig\n",
    "\n",
    "    def report(self, term_elim_times:list, start, end):\n",
    "        print(f\"Summary of PK data: \\n{self.summarize()}\\n\\n\")\n",
    "        print(\"Results of NCA:\\n\")\n",
    "        print(f\"Cmax: \\n{self.cmax()}\\n\\n\")\n",
    "        print(f\"Tmax: \\n{self.tmax()}\\n\\n\")\n",
    "        print(f\"t1/2: \\n{self.half_life(term_elim_times=term_elim_times)}\\n\\n\")\n",
    "        print(f\"AUC({start}-{end}): \\n{self.auc(start=start, end=end)}\\n\\n\")\n",
    "        print(f\"Vd: \\n{self.vd(silence_message=True)}\\n\\n\")\n",
    "        print(f\"CL: \\n{self.cl(start=start, end = end, silence_message=True)}\\n\\n\")\n",
    "\n",
    "    def report_df(self, term_elim_times:list, start, end):\n",
    "        print(\"hello world\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
